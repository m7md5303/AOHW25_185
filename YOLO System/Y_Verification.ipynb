{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37182f93-014d-44fe-a3b3-e2b9cb78e8cc",
   "metadata": {},
   "source": [
    "# This notebook is for verifying the genrated internal ONNX graphs generated during the flow before the HW Conversion\n",
    "### The main base for the verification process is the FINN function  finn.core.onnx_exec.execute_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09f245-751f-4b70-8724-49024ffa0a67",
   "metadata": {},
   "source": [
    "## First Step:\n",
    "Importing important libraries and base files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3807d921-81ea-4d4a-9d66-d6bc8651319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "import os\n",
    "\n",
    "build_dir = '/home/drmervat/Desktop/YOLO_GP/YOLO__VER'\n",
    "onnx_dir = '/home/drmervat/Desktop/YOLO_GP/YOLO__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6a8e63-6612-4748-a4b1-b7b87cd31623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef52192-4503-470b-b216-cabae6cb28d9",
   "metadata": {},
   "source": [
    "## Validating the output\n",
    "In this cell you can check the output values from each generated ONNX graph and compare it with the original model. Just replace the onnx file in line 35 with yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3161682a-4523-4e2f-a64d-4c7f10dce758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47842395\n"
     ]
    }
   ],
   "source": [
    "#using detect class\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "test_img_paths = glob.glob(\"stimulusgrid.jpg\")\n",
    "\n",
    "for number, test_img_path in enumerate(test_img_paths):\n",
    "    img_org = cv2.imread(test_img_path)\n",
    "    img = img_org.copy()\n",
    "    img\n",
    "    # Define the desired dimensions for the resized image\n",
    "    width = 416\n",
    "    height = 416\n",
    "\n",
    "    # # Resize the image\n",
    "    resized_image = cv2.resize(img, (width, height))\n",
    "\n",
    "    # Save the resized image\n",
    "    cv2.imwrite('stimulusgrid_resized.jpg', resized_image)\n",
    "    resized_image = resized_image[:, :, ::-1]\n",
    "    resized_image = resized_image.astype(np.float32)\n",
    "    resized_image_ip = resized_image.astype(np.uint8)\n",
    "    # resized_image_ip = resized_image_ip.transpose(2,1,0)\n",
    "    driver_in = np.expand_dims(resized_image_ip, 0)\n",
    "    driver_in = driver_in.astype(np.float32)\n",
    "    driver_in = driver_in.transpose(0,3,1,2)\n",
    "    # driver_in_ip = np.expand_dims(resized_image_ip, 0)\n",
    "    # driver_in_ip = driver_in_ip.transpose(0,3,1,2)\n",
    "    #ready the input\n",
    "    import numpy as np\n",
    "    import onnx.numpy_helper as nph\n",
    "    from qonnx.core.modelwrapper import ModelWrapper\n",
    "    input_dict = {\"global_in\": (driver_in)}\n",
    "    #simulating\n",
    "    model_for_sim = ModelWrapper(onnx_dir+\"/yolo_streamlined.onnx\")\n",
    "    import finn.core.onnx_exec as oxe\n",
    "    output_dict = oxe.execute_onnx(model_for_sim, input_dict, return_full_exec_context=False)\n",
    "    output_pysim = output_dict[list(output_dict.keys())[0]]\n",
    "    output_pysim=output_pysim.transpose(0,2,3,1)\n",
    "    output_pysim_arr=np.array(output_pysim)\n",
    "    conf = output_pysim_arr[0,:,:,10]/2+0.5\n",
    "    conf=conf * (output_pysim_arr[0,:,:,11]/2+0.5)\n",
    "    print(conf.max())\n",
    "    # nc  = 1\n",
    "    # anchors = np.array([[10,14,23,27,37,58]]) / np.array([32])\n",
    "    # torch.Tensor(output_pysim)\n",
    "    # detect_head = Detect(nc, anchors)\n",
    "    # pred = detect_head([output_pysim])[0]\n",
    "    # pred = non_max_suppression(pred, conf_thres=0.3, iou_thres=0.10, classes=None, max_det=10)\n",
    "    # print(np.array(pred).shape)\n",
    "    # #print(pred[0,0:12,4])\n",
    "    # #arr = (np.array(pred[0,:,4]))\n",
    "    # arr = (np.array(pred))\n",
    "    # max_val = arr[0,:,4].max()  # or np.max(arr)\n",
    "    # min_val = arr[0,:,4].min()  # or np.min(arr)\n",
    "    # print(max_val, min_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c661be9-62e6-4886-8ce3-494ee4497d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
