{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d08bcb-0822-4aef-a4f6-b47ece4316a6",
   "metadata": {},
   "source": [
    "# This Notebook is for the transformation of a pre-trained LPYOLO model using FINN Framework\n",
    "It ends up with generating a stitched IP for the network and a Vivado project for the target board (ZCU102 in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2b2de-4ae9-414e-8395-f0865a5650a5",
   "metadata": {},
   "source": [
    "## The first step is:\n",
    "importing basic functions andd setting the building Directory\n",
    "showInNetron is for visulaizing the ONNX graphs which can act as a double-check on the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85828755-7948-4ee5-87c7-c4b315f2974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "import os\n",
    "import onnx\n",
    "import torch \n",
    "\n",
    "build_dir = '/home/drmervat/Desktop/YOLO_GP/YOLO__'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58205bb7-dc05-419e-95a4-53633a813551",
   "metadata": {},
   "source": [
    "## For more details about the following imports, you can refer to the main FINN repository.\n",
    "However, they are mainly for the network tidying before going into the flow such as GiveUniqueNodeNames or for dealing with the model in its ONNX format through an API-like or a handle function such as ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5635ff-2997-478c-a1ba-953dbae787bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de94139a-8551-4aa9-b66e-f0bc7bb69311",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_onnx_path = build_dir + \"/yolo_export.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e300025e-17f9-4b2e-aad4-590bb4a0c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_export.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f18e025ba30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/yolo_export.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc5ac25-fc47-4c60-b8f3-1da4cc8304ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(export_onnx_path)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + \"/yolo_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01aee25f-d3e8-4568-9511-c4178a1a872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f18e025b640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/yolo_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d547b-041e-4bfe-a792-c2da0a11d2f0",
   "metadata": {},
   "source": [
    "## Pre-processing Node\n",
    "In BNN (Binarized Neural Networks), a pre-processing is done prior to training through Brevitas library where the RGB 8-bit input is divided by 255 to normalize the pixels to be between 0 and 1\n",
    "So, a pre-processing built-in node which performs the mentioned function above was used to achieve the same behaviour in case of inference on software-platforms\n",
    "This node is then merged to the main network and wrapped in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbab2bab-d48d-466a-8648-08f71870537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drmervat/Desktop/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/drmervat/Desktop/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "\n",
    "model = ModelWrapper(build_dir+\"/yolo_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+\"/yolo_preproc.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e0a35-40e0-4e1c-8b29-cd0afcb27766",
   "metadata": {},
   "source": [
    "### Now tidying is performed again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e156d4ee-dffb-4db3-b7a0-202800134b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "chkpt_name = build_dir+\"/yolo_preproc_tidy.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e007f40-f39b-4787-bdd0-37a5dba2bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_preproc_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f18f2ff64a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/yolo_preproc_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be4755-a49d-41eb-8acf-f17c082736d8",
   "metadata": {},
   "source": [
    "## Streamlining\n",
    "This can be considered as the core of power of FINN tool in which normal nodes are converted into layers capable of being transformed to Hardware modules as can be shown later\n",
    "For example maxpool layers are converted into MaxPoolNHWC through the MakeMaxPoolNHWC function \n",
    "(NHWC :\n",
    "N: number of tensors(inputs) per batch during inference\n",
    "H: height\n",
    "W: width\n",
    "C: number of channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b1f4b0-10c0-4432-85d3-26459612a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf13490-cb12-434f-903b-aec9a84372c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/yolo_preproc_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857d4565-d0a0-4763-b3aa-a2bbafac2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + \"/yolo_streamlined.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf7919e-3de7-41e6-9cef-65015f4f03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f18e025b850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/yolo_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39591a86-29a4-4146-b828-0cfcea9a5f0d",
   "metadata": {},
   "source": [
    "## More deep into the conversion process\n",
    "In this step the target board is chosen as well as the desired clock of the built project \n",
    "(you can refer to the main FINN repository for reviewing the supported boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2122584-9f8b-43c2-88b0-6cc6bf12b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"ZCU102\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 6.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dc858-c670-4ae1-b3c2-577dcf5eea2c",
   "metadata": {},
   "source": [
    "### HW Conversion\n",
    "In this step the layers from the streamlining are directly converted into hardware modules. These modules (nodes) can be instantiated whether in RTL or HLS. Moreover, you can choose your preference for each one whether you want it to be implemented using RTL or HLS Libraries. However, if you chose your preference for the MVAU node (for example) to be implemented using RTL and no RTL library for it in FINN sources, it would be directly implemented in HLS without errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad74dd3-097d-4b3c-9887-3823f4e5d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddac9563-f97f-40c9-9554-8e709e5885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/yolo_streamlined.onnx\")\n",
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + \"/yolo_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "dataflow_model.save(build_dir + \"/yolo_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8e375-9ac0-4f5c-9d3c-571ebcf274d0",
   "metadata": {},
   "source": [
    "## Parent and Child\n",
    "In the second half of the previous cell, a child model was extracted from the whole network. This child is the pure-hardware accelerator with no interaction from software. While the parent model consists of the whole network including this child model.\n",
    "For more declaration, see the two following Netron graphs for visulaizing both the parent and the child models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcfb5209-e01f-4615-bdc3-44c1eeda1f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f184429ad40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/yolo_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9712d7cc-0c42-4d2a-8f6e-e40599096a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f1844372920>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/yolo_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9c803-1631-48de-8e8d-f9328bf61fca",
   "metadata": {},
   "source": [
    "## Setting the Parallelism (Folding)\n",
    "In the following steps both input and output parallelism are set. As can be seen, in this project they were only edited for thr MVAU and ConvolutionINputGenerator nodes only. You can refer to the main LPYOLO repository for setting the parallelism values.\n",
    "### PE (Processing Element) values\n",
    "This maps to the parallelism in the input of the node\n",
    "### SIMD (Single INstruction Multiple Data) values\n",
    "This maps to the parallelism in the output of the node\n",
    "### FIFO_Depth values\n",
    "\n",
    "#### It is allowed to set different values for the nodes even if they are of the same type\n",
    "For example\n",
    "(MVAU_0 PE:4)\n",
    "(MVAU_1 PE:8)\n",
    "\n",
    "and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2affa7ed-19f2-4609-8770-cc640ef356b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/yolo_dataflow_model.onnx\")\n",
    "fc_layers = model.get_nodes_by_op_type(\"MVAU_hls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028d0405-90e0-4ade-8d56-9374064806b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each tuple is (PE, SIMD, in_fifo_depth) for a layer\n",
    "folding = [\n",
    "    (8, 9, [128]),\n",
    "    (8, 4, [128]),\n",
    "    (8, 4, [128]),\n",
    "    (8, 4, [128]),\n",
    "    (4, 4, [81]),\n",
    "    (4, 4, [4]),\n",
    "    (8, 4, [4]),\n",
    "    (4, 4, [128]),\n",
    "    (4, 4, [32]),\n",
    "    (1, 8, [32]),\n",
    "]\n",
    "\n",
    "for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepths\", ififodepth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "915ffe9d-814a-4a76-9b30-b98716cccb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator_rtl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ce248f-91cb-4ca6-ac68-dc470e530fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = [\n",
    "    (3),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "    (4),\n",
    "]\n",
    "for fcl, (simd) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8957d467-dfcb-43cb-bae2-4d9e454ef0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(build_dir + \"/yolo_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "261a2f5b-b0f3-4bf7-a8b6-85aa382000d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f18442c72e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/yolo_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50450a5-d518-4cb7-ade0-c7d1b0dda1b5",
   "metadata": {},
   "source": [
    "## Building the Project\n",
    "THe following cell is for building the Vivado ZYNQ project based on the final ONNX generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f499cfb2-08fd-4616-92a9-663661878920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drmervat/Desktop/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 52 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/home/drmervat/Desktop/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:234: UserWarning: Input FIFO for IODMA_hls_0_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/home/drmervat/Desktop/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:294: UserWarning: Output FIFO for MVAU_hls_9_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/home/drmervat/Desktop/finn/src/finn/transformation/fpgadataflow/create_stitched_ip.py:290: UserWarning: First node is not StreamingFIFO or IODMA.\n",
      "                You may experience incorrect stitched-IP rtlsim or hardware\n",
      "                behavior. It is strongly recommended to insert FIFOs prior to\n",
      "                calling CreateStitchedIP.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+\"/yolo_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70e7d0-c807-4774-95ac-7233ea6ad89e",
   "metadata": {},
   "source": [
    "## PYNQ Driver\n",
    "The following cell is for generating a PYNQ driver for running the project on a PYNQ kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fede8d6-38c0-4b14-8cf5-ce5f8885a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b2062fa-3a23-4f93-a92e-26990176ad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/home/drmervat/Desktop/YOLO_GP/YOLO__/yolo_synth.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7b4bfcace6e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(build_dir + \"/yolo_synth.onnx\")\n",
    "showInNetron(build_dir + \"/yolo_synth.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79385a3a-2382-4986-a4ca-d24440f46229",
   "metadata": {},
   "source": [
    "## Printing important files' paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b37b82bc-555d-402e-8b62-c830324ca7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[key: \"floorplan_json\"\n",
       "value: \"/tmp/finn_dev_drmervat/vitis_floorplan_ngariqe_/floorplan.json\"\n",
       ", key: \"vivado_pynq_proj\"\n",
       "value: \"/tmp/finn_dev_drmervat/vivado_zynq_proj_613zsnsw\"\n",
       ", key: \"bitfile\"\n",
       "value: \"/tmp/finn_dev_drmervat/vivado_zynq_proj_613zsnsw/resizer.bit\"\n",
       ", key: \"hw_handoff\"\n",
       "value: \"/tmp/finn_dev_drmervat/vivado_zynq_proj_613zsnsw/resizer.hwh\"\n",
       ", key: \"vivado_synth_rpt\"\n",
       "value: \"/tmp/finn_dev_drmervat/vivado_zynq_proj_613zsnsw/synth_report.xml\"\n",
       ", key: \"platform\"\n",
       "value: \"zynq-iodma\"\n",
       ", key: \"pynq_driver_dir\"\n",
       "value: \"/tmp/finn_dev_drmervat/pynq_driver_s2jzmsjk\"\n",
       "]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper(build_dir + \"/yolo_synth.onnx\")\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5369852-af21-4b00-baf4-18e1bc87101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finn_zynq_link.cache\t      finn_zynq_link.runs  resizer.bit\t     vivado.jou\n",
      "finn_zynq_link.gen\t      finn_zynq_link.srcs  resizer.hwh\t     vivado.log\n",
      "finn_zynq_link.hw\t      finn_zynq_link.xpr   synth_project.sh\n",
      "finn_zynq_link.ip_user_files  ip_config.tcl\t   synth_report.xml\n"
     ]
    }
   ],
   "source": [
    "! ls {model.get_metadata_prop(\"vivado_pynq_proj\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586861dd-4979-4bf6-9173-8d3c56dd7bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
